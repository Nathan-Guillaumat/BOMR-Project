{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border:1px solid black; padding:20px 20px;text-align: justify;text-justify: inter-word\">\n",
    "    <strong>Project - Motor Control \n",
    "    \n",
    "\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Imports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Variance for position :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpx = 0.25 # variance on position state\n",
    "qpy = 0.25\n",
    "rpx = 0.04 # variance on position measurement \n",
    "rpy = 0.04\n",
    "\n",
    "qpx = 0.25 # variance on position state\n",
    "qpy = 0.25 \n",
    "rpx = 0.01 # variance on position measurement \n",
    "rpy = 0.01\n",
    "\n",
    "std_speed = 11.77\n",
    "q_theta_nu = std_speed/2 # variance on speed state\n",
    "r_theta_nu = 0.1# std_speed/2 # variance on speed measurement \n",
    "\n",
    "# Initialising the remaining constants\n",
    "# units: length [mm], time [s]\n",
    "A = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "Q = np.array([[qpx, 0, 0], [0, qpy, 0],[0, 0, q_theta_nu]]); #w matrix\n",
    "rotation_conv_factor = 0.41; #0.8 for 50 speed, 0.41 for 100 speed\n",
    "speed_conv_factor_straight = 0.338; #straight\n",
    "speed_conv_factor_left = 0.403;\n",
    "speed_conv_factor_right = 0.425;\n",
    "\n",
    "speed_conv_factor = 0.374 #mean of the two\n",
    "transition_thresh = 500\n",
    "l = 100 #mm, distance between the two wheels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globalNavigation import *\n",
    "from helpers import *\n",
    "from vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main (from her on, keep in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 0102d6c0-0c6c-479f-8406-474092b0daba"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up thymio\n",
    "\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 19:24:27.460 Python[11981:592403] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    }
   ],
   "source": [
    "# Open the video capture\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def path_following(motor_speed=100, threshold=0,  verbose=False):\n",
    "    \n",
    "    global n, positions, x_est, P_est, Ts, read, Vr, Vl, n\n",
    "\n",
    "    saw_obstacle = False\n",
    "    \n",
    "    if verbose: print(\"\\t Path following \")\n",
    "    await node.set_variables(motors(motor_speed, motor_speed))\n",
    "           \n",
    "    prev_state=\"local\"\n",
    "    \n",
    "    while not saw_obstacle:\n",
    "        \n",
    "        if test_saw_obstacle(threshold, verbose=False):\n",
    "            if prev_state==\"local\": \n",
    "                prev_state=\"global\"\n",
    "            saw_obstacle = True\n",
    "            await client.sleep(0.1) #otherwise, variables would not be updated\n",
    "        else:\n",
    "            start = time.time()\n",
    "            if (positions[n][0]+position_threshold > x_est[0][0]) and (positions[n][0]-position_threshold < x_est[0][0]):\n",
    "                if (positions[n][1]+position_threshold > x_est[1][0]) and (positions[n][1]-position_threshold < x_est[1][0]):\n",
    "                    n+=1\n",
    "            angle = angle_to_rotate([x_est[0][0],x_est[1][0]],positions[n],x_est[2][0]);\n",
    "            print(\"-------angle--------\",angle)\n",
    "            if (abs(angle)<angle_threshold):\n",
    "                drive_task = asyncio.create_task(drive_for_seconds(client, Ts))\n",
    "                await drive_task\n",
    "            else:\n",
    "                if angle>0:\n",
    "                    right = 1\n",
    "                else:\n",
    "                    right = 0\n",
    "\n",
    "                turn_task = asyncio.create_task(turn_for_seconds(client, Ts, right))\n",
    "                await turn_task\n",
    "            stop = time.time()\n",
    "            \n",
    "    return \n",
    "\n",
    "\n",
    "def test_saw_obstacle(threshold, verbose=True):\n",
    "    print(\"\\t Test saw obstacle: \")\n",
    "    if any([x > threshold for x in node['prox.horizontal'][0:5]]):\n",
    "        if verbose: print(\"\\t\\t Obstacle detected\")\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "async def local_avoidance(motor_speed=100, threshold=0, verbose=False):\n",
    "    obstacleSpeedGain = [6, 4, -2, -6, -8]\n",
    "    saw_obstacle = True\n",
    "    speedL = motor_speed\n",
    "    speedR = motor_speed\n",
    "    prev_state = \"global\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Local avoidance\")\n",
    "\n",
    "    while saw_obstacle:\n",
    "        if test_saw_obstacle(threshold, verbose=False):\n",
    "            if prev_state == \"global\":\n",
    "                prev_state = \"local\"\n",
    "                print(\"\\t Transitioning to local avoidance\")\n",
    "\n",
    "            for i in range(5):\n",
    "                speedL += node[\"prox.horizontal\"][i] * obstacleSpeedGain[i] // 100\n",
    "                speedR += node[\"prox.horizontal\"][i] * obstacleSpeedGain[4 - i] // 100\n",
    "\n",
    "          \n",
    "            await node.set_variables(motors(speedL, speedR))\n",
    "            if verbose:\n",
    "                print(\"\\t\\t Adjusting for obstacle\")\n",
    "\n",
    "        else:\n",
    "            saw_obstacle = False\n",
    "            if prev_state == \"local\":\n",
    "                #prev_state = \"global\"\n",
    "                print(prev_state)\n",
    "                print(\"\\t Transitioning to global navigation\")\n",
    "                \n",
    "            \n",
    "\n",
    "            # Reset motor speeds when no obstacles are detected\n",
    "            speedL = motor_speed\n",
    "            speedR = motor_speed\n",
    "            await node.set_variables(motors(speedL, speedR))\n",
    "            \n",
    "            # Add a small delay to avoid continuously checking for obstacles too quickly\n",
    "            await client.sleep(0.1)\n",
    "\n",
    "async def drive_for_seconds(client, seconds):\n",
    "    # Set the motor speeds\n",
    "    v = {\n",
    "        \"motor.left.target\": [int(99)],\n",
    "        \"motor.right.target\": [int(100)],\n",
    "    }\n",
    "    await node.set_variables(v)\n",
    "    await asyncio.sleep(seconds)\n",
    "\n",
    "\n",
    "async def turn_for_seconds(client, seconds,right):\n",
    "    # Set the motor speeds\n",
    "    if seconds != 0:\n",
    "        if right==1:\n",
    "            v = {\n",
    "                \"motor.left.target\": [int(100)],\n",
    "                \"motor.right.target\": [int(-100)],\n",
    "            }\n",
    "        else:\n",
    "            v = {\n",
    "                \"motor.left.target\": [int(-100)],\n",
    "                \"motor.right.target\": [int(100)],\n",
    "            }\n",
    "        await node.set_variables(v)\n",
    "    await asyncio.sleep(abs(seconds))\n",
    "\n",
    "def camera_acquisition():\n",
    "    global frame, image_ready\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    image_ready = True\n",
    "\n",
    "def filter():\n",
    "    global x_est, P_est, Ts, angle, Vr, Vl, frame, image_ready\n",
    "\n",
    "    thymio_data.append({\"left_speed\":node[\"motor.left.speed\"],\n",
    "                        \"right_speed\":node[\"motor.right.speed\"]}) \n",
    "\n",
    "    Vl = thymio_data[-1][\"left_speed\"]\n",
    "    Vr = thymio_data[-1][\"right_speed\"]\n",
    "\n",
    "    camera_x = 0\n",
    "    camera_y = 0\n",
    "    camera_angle = 0\n",
    "\n",
    "    if image_ready:\n",
    "        thymio_result = locate_thymio(frame)\n",
    "        camera_x = thymio_result[0][0][0]*0.4\n",
    "        camera_y = thymio_result[0][0][1]*0.4\n",
    "        camera_angle = (thymio_result[2])*360/(2*np.pi)\n",
    "        image_ready = False\n",
    "\n",
    "    x_est, P_est = kalman_filter(x_est, P_est, Vr, Vl, Ts, camera_x, camera_y, camera_angle)\n",
    "    camera_x = 0 \n",
    "\n",
    "def kalman_filter( x_est_prev, P_est_prev, Vr, Vl, Ts, camera_x=0, camera_y=0, camera_angle=0,):\n",
    "\n",
    "    ## Prediciton through the a priori estimate\n",
    "    # estimated mean of the state\n",
    "    if abs(Vr-Vl) < 30:\n",
    "        speed_conv_factor = speed_conv_factor_straight\n",
    "    elif Vr<Vl:\n",
    "        speed_conv_factor = speed_conv_factor_right\n",
    "    else:\n",
    "        speed_conv_factor = speed_conv_factor_left\n",
    "    \n",
    "    orientation = np.double(x_est_prev[2][0]%360)*2*np.pi/360\n",
    "    #x_est_prev[2][0] = orientation\n",
    "    B = np.array([[Ts*np.cos(orientation)/2,Ts*np.cos(orientation)/2],\n",
    "         [Ts*np.sin(orientation)/2,Ts*np.sin(orientation)/2],\n",
    "         [-Ts*360/(l*2*np.pi), Ts*360/(l*2*np.pi)]])\n",
    "    U = np.array([[Vr*speed_conv_factor],[Vl*speed_conv_factor]])\n",
    "    x_est_a_priori = np.dot(A, x_est_prev) + np.dot(B, U);\n",
    "\n",
    "    # Estimated covariance of the state\n",
    "    P_est_a_priori = np.dot(A, np.dot(P_est_prev, A.T));\n",
    "    P_est_a_priori = P_est_a_priori + Q if type(Q) != type(None) else P_est_a_priori\n",
    "        \n",
    "    ## Update         \n",
    "    # y, C, and R for a posteriori estimate, depending on transition\n",
    "    if (camera_x != 0) : #XOR (one or the other but not both)\n",
    "        # transition detected aka camera provides the position\n",
    "        y = np.array([[camera_x],[camera_y],[camera_angle]])\n",
    "        H = np.array([[1, 0, 0],[0, 1, 0],[0, 0, 1]])\n",
    "        R = np.array([[rpx, 0, 0],[0, rpy,0],[0, 0, r_theta_nu]]) #not the value of the variance of the position measurments\n",
    "        \n",
    "        # innovation / measurement residual\n",
    "        i = y - np.dot(H, x_est_a_priori); #measured-mean aka difference between the two states\n",
    "        # measurement prediction covariance\n",
    "        S = np.dot(H, np.dot(P_est_a_priori, H.T)) + R;\n",
    "                 \n",
    "        # Kalman gain (tells how much the predictions should be corrected based on the measurements)\n",
    "        K = np.dot(P_est_a_priori, np.dot(H.T, np.linalg.inv(S)));\n",
    "            \n",
    "        # a posteriori estimate\n",
    "        x_est = x_est_a_priori + np.dot(K,i);\n",
    "        P_est = P_est_a_priori - np.dot(K,np.dot(H, P_est_a_priori));\n",
    "\n",
    "    else:\n",
    "        x_est = x_est_a_priori\n",
    "        P_est = P_est_a_priori\n",
    "     \n",
    "    return x_est, P_est\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexei.ermochkine/Desktop/ma3/mobile_robotics/venv4mobilerobotics/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position : [[  32.40277778  485.20833333]\n",
      " [1448.          530.        ]]\n",
      "entered try\n",
      "\t Path following \n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.0892906841201464\n",
      "-------angle-------- -0.3546594769357767\n",
      "\t Test saw obstacle: \n",
      "theta-i:  3.808654705564476\n",
      "-------angle-------- -2.1364077400023995\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.984589709200693\n",
      "-------angle-------- -1.3268475941662223\n",
      "\t Test saw obstacle: \n",
      "theta-i:  -0.4498090769137817\n",
      "-------angle-------- 1.9596133585284194\n",
      "\t Test saw obstacle: \n",
      "theta-i:  1.7881590864548556\n",
      "-------angle-------- -0.2166255056874451\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.4352785644761883\n",
      "-------angle-------- -0.7993118366617809\n",
      "\t Test saw obstacle: \n",
      "theta-i:  1.4586546947578514\n",
      "-------angle-------- 0.057728168906464816\n",
      "\t Test saw obstacle: \n",
      "theta-i:  0.4758817829235409\n",
      "-------angle-------- 0.9983238052441346\n",
      "\t Test saw obstacle: \n",
      "theta-i:  0.05730973576087006\n",
      "-------angle-------- 1.5036650229337314\n",
      "\t Test saw obstacle: \n",
      "theta-i:  3.428442271502845\n",
      "-------angle-------- -1.8567213254653665\n",
      "\t Test saw obstacle: \n",
      "theta-i:  4.386139354163924\n",
      "-------angle-------- -2.6985903606529025\n",
      "\t Test saw obstacle: \n",
      "theta-i:  1.7788846752113612\n",
      "-------angle-------- -0.3340074561097739\n",
      "\t Test saw obstacle: \n",
      "theta-i:  1.0684627554288983\n",
      "-------angle-------- 0.35590213763518785\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.651855260546287\n",
      "-------angle-------- -1.1649381159325731\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.526818858903103\n",
      "-------angle-------- -1.021510067123004\n",
      "\t Test saw obstacle: \n",
      "theta-i:  0.8481517769292527\n",
      "-------angle-------- 0.601452618513291\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.542870085463228\n",
      "-------angle-------- -1.0609006626135413\n",
      "\t Test saw obstacle: \n",
      "theta-i:  5.513726621795828\n",
      "-------angle-------- -4.020890130083276\n",
      "\t Test saw obstacle: \n",
      "theta-i:  1.4284289844935247\n",
      "-------angle-------- -0.01925230804085376\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.9280301078993314\n",
      "-------angle-------- -1.535413304894213\n",
      "\t Test saw obstacle: \n",
      "theta-i:  -0.14651999964560147\n",
      "-------angle-------- 1.4583567093543612\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.8898167494792206\n",
      "-------angle-------- -1.4865238688954712\n",
      "\t Test saw obstacle: \n",
      "theta-i:  2.161514869783504\n",
      "-------angle-------- -0.7251832329964953\n",
      "\t Test saw obstacle: \n",
      "theta-i:  0.4076886068502062\n",
      "-------angle-------- 0.9910199564672779\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "thymio_data = []\n",
    "initial_orientation = 0 #degree\n",
    "\n",
    "global image_ready\n",
    "image_ready = False\n",
    "\n",
    "# Read the first frame from the video capture\n",
    "ret, init_frame = cap.read()\n",
    "\n",
    "# Applying vision functions\n",
    "thymio_result = locate_thymio(init_frame)\n",
    "obstacles_result = locate_static_obstacles(init_frame, 150)\n",
    "goal_result = locate_goal(init_frame)  \n",
    "\n",
    "start = Point(thymio_result[0][0][0], thymio_result[0][0][1])\n",
    "goal = Point(goal_result[0], goal_result[1])\n",
    "# table_origin = Point(table_origin_result[0], table_origin_result[1])\n",
    "\n",
    "# \n",
    "polys = []\n",
    "poly = []\n",
    "n_polys=0\n",
    "for polygone in obstacles_result:\n",
    "    n_polys += 1\n",
    "    for corner in polygone:\n",
    "        poly.append(Point(corner[0],corner[1]))\n",
    "    polys.append(poly)\n",
    "    poly = []\n",
    "\n",
    "#polys = [[Point(170, 599), Point(170,731), Point(291,731), Point(291, 599)], [Point(431, 432), Point(398,489), Point(431, 550), Point(501, 550), Point(535, 491), Point(503, 435)], [Point(78, 129), Point(78,420), Point(531, 420), Point(531,129)]]\n",
    "#start = Point(76, 81)\n",
    "#goal = Point(498, 762)\n",
    "\n",
    "positions = global_navigation(polys, start, goal, [1920,1080]) * 0.4\n",
    "initial_orientation = thymio_result[2]*360/(2*np.pi)\n",
    "\n",
    "print(\"Initial position :\", positions/0.4)\n",
    "\n",
    "#print(positions[0][0])\n",
    "#positions = np.array([[0,0],[200,100],[10,30]])#[0,0],[30,45],[50,50],[17,15],[50,10]\n",
    "angle_threshold = 10 #degrees\n",
    "x_est = np.array([[positions[0][0]], [positions[0][1]], [initial_orientation]])\n",
    "P_est = 0\n",
    "Ts = 0.1\n",
    "count = 0\n",
    "Vr = 0\n",
    "Vl = 0\n",
    "position_threshold = 10\n",
    "ret = 0\n",
    "\n",
    "n = 1\n",
    "await node.wait_for_variables() # wait for Thymio variables values\n",
    "rt = RepeatedTimer(Ts, filter)#, x_est, P_est, Ts)\n",
    "rt_camera = RepeatedTimer(Ts, camera_acquisition)#, x_est, P_est, Ts)\n",
    "\n",
    "try:\n",
    "    print(\"entered try\")\n",
    "    for i in range(10):\n",
    "        await path_following(verbose=True)\n",
    "        await local_avoidance(verbose=True)\n",
    "    #node.send_set_variables(motors(0, 0))\n",
    "finally:\n",
    "    rt.stop()\n",
    "    node.send_set_variables(motors(0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
